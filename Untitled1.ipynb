{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593eea63",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # ###############\n",
    "        # dir = r'polution_data/'\n",
    "        # files = os.listdir(dir)\n",
    "        # target = 'pm2.5'\n",
    "        # cols = [\n",
    "        #     'DEWP',\n",
    "        #     'TEMP',\n",
    "        #     'PRES',\n",
    "        #     'cbwd',\n",
    "        #     'Iws',\n",
    "        #     'Is',\n",
    "        #     'Ir'\n",
    "        # ]\n",
    "        train_datasets={}\n",
    "        val_datasets={}\n",
    "        test_datasets={}\n",
    "\n",
    "        start=True\n",
    "        for file in files:\n",
    "            print(file)\n",
    "            file_path=dir+file\n",
    "            data = pd.read_csv(file_path)\n",
    "            site_colms=data.columns.values.tolist()\n",
    "            site_final_cols=copy.deepcopy(cols)\n",
    "            length=data.shape[0]\n",
    "            data1=data\n",
    "            X_train1 = np.zeros((len(data1), depth, len(site_final_cols)))\n",
    "            for i, name in enumerate(site_final_cols):\n",
    "                for j in range(depth):\n",
    "                    X_train1[:, j, i] = data1[name].shift(depth - j - 1)#.fillna(method=\"bfill\")\n",
    "            y_train1 = np.array(data1[target].shift(-prediction_horizon))#.fillna(method='ffill'))\n",
    "            X_train1 = X_train1[depth:-prediction_horizon]\n",
    "            y_train1 = y_train1[depth:-prediction_horizon]\n",
    "            y_nan_mask=np.isnan(y_train1) | np.isinf(y_train1)\n",
    "            y_extreme_mask=np.abs(y_train1)>pow(10,5)\n",
    "            y_nan_mask=(y_nan_mask | y_extreme_mask)\n",
    "            x_temp=X_train1.reshape((X_train1.shape[0],-1)).copy()\n",
    "            x_nan_mask=np.any(np.isnan(x_temp),axis=1) | np.any(np.isinf(x_temp),axis=1)\n",
    "            x_extreme_mask=np.any(np.abs(x_temp)>pow(10,5),axis=1)\n",
    "            x_nan_mask=(x_nan_mask|x_extreme_mask)\n",
    "            nan_mask=(y_nan_mask | x_nan_mask)\n",
    "            if np.sum(nan_mask==False)>0:\n",
    "                X_train1=X_train1[nan_mask==False]\n",
    "                y_train1 = y_train1[nan_mask == False]\n",
    "                all_idxs = [item_idx for item_idx in range(y_train1.shape[0])]\n",
    "                test_idxs = random.sample(all_idxs, int(test_precent * len(all_idxs)))\n",
    "                train_validate_idxs = list(set(all_idxs).difference(set(test_idxs)))\n",
    "                validate_idxs = random.sample(train_validate_idxs, int(1 / 9 * len(train_validate_idxs)))\n",
    "                train_idxs = np.array(list(set(train_validate_idxs).difference(set(validate_idxs))))\n",
    "                test_idxs = np.array(test_idxs)\n",
    "                validate_idxs = np.array(validate_idxs)\n",
    "                if start:\n",
    "                    train_datasets['X']=X_train1[train_idxs]\n",
    "                    train_datasets['Y'] = y_train1[train_idxs]\n",
    "                    test_datasets['X'] = X_train1[test_idxs]\n",
    "                    test_datasets['Y'] = y_train1[test_idxs]\n",
    "                    val_datasets['X'] = X_train1[validate_idxs]\n",
    "                    val_datasets['Y'] = y_train1[validate_idxs]\n",
    "                    start=False\n",
    "                else:\n",
    "                    train_datasets['X'] = np.concatenate([train_datasets['X'],X_train1[train_idxs]], axis=0)\n",
    "                    train_datasets['Y'] = np.concatenate([train_datasets['Y'],y_train1[train_idxs]], axis=0)\n",
    "                    test_datasets['X'] = np.concatenate([test_datasets['X'], X_train1[test_idxs]],\n",
    "                                                                    axis=0)\n",
    "                    test_datasets['Y'] = np.concatenate([test_datasets['Y'], y_train1[test_idxs]],axis=0)\n",
    "                    val_datasets['X'] = np.concatenate(\n",
    "                        [val_datasets['X'], X_train1[validate_idxs]], axis=0)\n",
    "                    val_datasets['Y'] = np.concatenate(\n",
    "                        [val_datasets['Y'], y_train1[validate_idxs]], axis=0)\n",
    "        print(train_datasets.keys())\n",
    "\n",
    "        x_train=train_datasets['X']\n",
    "        y_train=train_datasets['Y']\n",
    "        x_test = test_datasets['X']\n",
    "        y_test = test_datasets['Y']\n",
    "        x_validate = val_datasets['X']\n",
    "        y_validate = val_datasets['Y']\n",
    "        x_all = np.concatenate((x_train, x_validate, x_test), axis=0)\n",
    "        y_all = np.concatenate((y_train, y_validate, y_test), axis=0)\n",
    "        x_means=np.nanmean(x_all.reshape((-1,x_all.shape[2])),axis=0)\n",
    "        x_std=np.nanstd(x_all.reshape((-1,x_all.shape[2])),axis=0)\n",
    "        y_means=np.nanmean(y_all,axis=0)\n",
    "        y_std = np.nanstd(y_all, axis=0)\n",
    "        x_train=(x_train-x_means)/(x_std+pow(10,-6))\n",
    "        y_train=(y_train-y_means)/(y_std+pow(10,-6))\n",
    "        x_test=(x_test-x_means)/(x_std+pow(10,-6))\n",
    "        y_test=(y_test-y_means)/(y_std+pow(10,-6))\n",
    "        x_validate = (x_validate - x_means) / (x_std + pow(10, -6))\n",
    "        y_validate = (y_validate - y_means) / (y_std + pow(10, -6))\n",
    "\n",
    "        x_train = torch.Tensor(x_train)\n",
    "        x_test = torch.Tensor(x_test)\n",
    "        y_train = torch.Tensor(y_train)\n",
    "        y_test = torch.Tensor(y_test)\n",
    "        x_validate = torch.Tensor(x_validate)\n",
    "        y_validate = torch.Tensor(y_validate)\n",
    "\n",
    "        train_loader = DataLoader(TensorDataset(x_train, y_train), shuffle=True, batch_size=batch_size)\n",
    "        val_loader = DataLoader(TensorDataset(x_validate, y_validate), shuffle=False, batch_size=batch_size)\n",
    "        test_loader = DataLoader(TensorDataset(x_test, y_test), shuffle=False, batch_size=batch_size)\n",
    "\n",
    "        device='cpu'\n",
    "        him_dim=4\n",
    "        model = LSTMNet(x_train.shape[2],  him_dim, 1,device=device,dropout_rate=0.1).to(device=device)#.cuda()#input_dim, hidden_dim, output_dim,dropout_rate=0,device='cpu'\n",
    "        opt = torch.optim.Adam(model.parameters(), lr=0.01,)#weight_decay=pow(10,-3)\n",
    "        epoch_scheduler = torch.optim.lr_scheduler.StepLR(opt, 1, gamma=0.9)\n",
    "        epochs = 40\n",
    "        loss = nn.MSELoss()\n",
    "        patience = 50\n",
    "        min_val_loss = 9999\n",
    "        counter = 0\n",
    "        para_path=f\"lstm_phenology_{him_dim}_seed{seed}_lag{depth}.pt\"\n",
    "        if os.path.exists(para_path):\n",
    "            model.load_state_dict(torch.load(para_path))\n",
    "        for i in range(epochs):\n",
    "            mse_train = 0\n",
    "            iteration_start = time.monotonic()\n",
    "            model.train()\n",
    "            for batch_x, batch_y in train_loader:\n",
    "                batch_x = batch_x.to(device=device)#.cuda()\n",
    "                batch_y = batch_y.to(device=device)#.cuda()\n",
    "                opt.zero_grad()\n",
    "                y_pred= model(batch_x)\n",
    "                y_pred = y_pred.squeeze(1)\n",
    "                l = loss(y_pred, batch_y)\n",
    "                l.backward()\n",
    "                mse_train += l.item() * batch_x.shape[0]\n",
    "                opt.step()\n",
    "            epoch_scheduler.step()\n",
    "            # validate\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                mse_val = 0\n",
    "                preds = []\n",
    "                true = []\n",
    "                for batch_x, batch_y in val_loader:\n",
    "                    batch_x = batch_x.to(device=device)#.cuda()\n",
    "                    batch_y = batch_y.to(device=device)#.cuda()\n",
    "                    output= model(batch_x)\n",
    "                    output = output.squeeze(1)\n",
    "                    preds.append(output.cpu().numpy())\n",
    "                    true.append(batch_y.cpu().numpy())\n",
    "                    mse_val += loss(output, batch_y).item() * batch_x.shape[0]\n",
    "            preds = np.concatenate(preds)\n",
    "            true = np.concatenate(true)\n",
    "\n",
    "            if min_val_loss > mse_val ** 0.5:\n",
    "                min_val_loss = mse_val ** 0.5\n",
    "                print(\"Saving...\")\n",
    "                torch.save(model.state_dict(), para_path)\n",
    "                counter = 0\n",
    "            else:\n",
    "                counter += 1\n",
    "\n",
    "            if counter == patience:\n",
    "                break\n",
    "            print(\"Iter: \", i, \"train: \", (mse_train / len(x_train)) ** 0.5, \"val: \", (mse_val / len(x_train)) ** 0.5)\n",
    "            iteration_end = time.monotonic()\n",
    "            print(\"Iter time: \", iteration_end - iteration_start)\n",
    "            if (i % 10 == 0):\n",
    "                preds = preds * (y_std+pow(10,-6)) + y_means\n",
    "                true = true * (y_std+pow(10,-6)) + y_means\n",
    "                mse = mean_squared_error(true, preds)\n",
    "                mae = mean_absolute_error(true, preds)\n",
    "                r=stats.pearsonr(true, preds)[0]\n",
    "                print(\"mse: \", mse, \"mae: \", mae,'r:',r)\n",
    "                # plt.figure(figsize=(6, 5))\n",
    "                # plt.plot(preds)\n",
    "                # plt.plot(true)\n",
    "                # plt.show()\n",
    "\n",
    "        # test\n",
    "        model.load_state_dict(torch.load(para_path))\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            mse_val = 0\n",
    "            preds = []\n",
    "            true = []\n",
    "            for batch_x, batch_y in test_loader:\n",
    "                batch_x = batch_x.to(device=device)#.cuda()\n",
    "                batch_y = batch_y.to(device=device)#.cuda()\n",
    "                output= model(batch_x)\n",
    "                output = output.squeeze(1)\n",
    "                preds.append(output.cpu().numpy())\n",
    "                true.append(batch_y.cpu().numpy())\n",
    "                mse_val += loss(output, batch_y).item()*batch_x.shape[0]\n",
    "        preds = np.concatenate(preds)\n",
    "        true = np.concatenate(true)\n",
    "\n",
    "        preds = preds*(y_std+pow(10,-6)) + y_means\n",
    "        true = true*(y_std+pow(10,-6)) + y_means\n",
    "\n",
    "        mse = mean_squared_error(true, preds)\n",
    "        mae = mean_absolute_error(true, preds)\n",
    "        plt.scatter(true,preds)\n",
    "        plt.show()\n",
    "        r=stats.pearsonr(true, preds)[0]\n",
    "        temp_result = ['lstm', seed, mae, r]\n",
    "        df_result.loc[df_idx] = temp_result\n",
    "        df_idx += 1\n",
    "        print(type, mse, mae,r)\n",
    "    df_result.to_csv(f'lstm_mae_r_lag{depth}.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
