{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35a14a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated data saved to G:\\Hangkai\\Forest_edge\\country_stats\\final_data\\aggregated_forest_edge_country.csv\n"
     ]
    }
   ],
   "source": [
    "# 读取CSV文件并转换为列表\n",
    "file_path = \"G:\\\\Hangkai\\\\Forest_edge\\\\country_stats\\\\final_data\\\\forest_edge_country.csv\"\n",
    "\n",
    "with open(file_path, 'r', encoding='ISO-8859-1') as f:\n",
    "    lines = f.readlines()\n",
    "    header = lines[0].strip().split(',')\n",
    "    lines = lines[1:]  # 仅获取数据，跳过标题行\n",
    "    \n",
    "    # 使用字典来整合重复的国家数据\n",
    "    data_dict = {}\n",
    "    for line in lines:\n",
    "        values = line.strip().split(',')\n",
    "        country = values[0]\n",
    "        \n",
    "        # 如果国家不在字典中，将其添加到字典中\n",
    "        if country not in data_dict:\n",
    "            data_dict[country] = [float(i) for i in values[1:]]\n",
    "        else:\n",
    "            # 如果国家已经在字典中，累加数据\n",
    "            for i in range(len(data_dict[country])):\n",
    "                data_dict[country][i] += float(values[i + 1])\n",
    "\n",
    "# 创建一个新的矩阵\n",
    "new_matrix = [header]\n",
    "for country, data in data_dict.items():\n",
    "    new_matrix.append([country] + data)\n",
    "\n",
    "# 将新的矩阵保存为CSV\n",
    "output_file_path = \"G:\\\\Hangkai\\\\Forest_edge\\\\country_stats\\\\final_data\\\\aggregated_forest_edge_country.csv\"\n",
    "with open(output_file_path, 'w', encoding='ISO-8859-1') as f:\n",
    "    for row in new_matrix:\n",
    "        f.write(','.join(map(str, row)) + '\\n')\n",
    "\n",
    "print(f\"Aggregated data saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54d6a55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to G:\\Hangkai\\Forest_edge\\country_stats\\final_data\\processed_country_data.csv\n"
     ]
    }
   ],
   "source": [
    "file_path = \"G:\\\\Hangkai\\\\Forest_edge\\\\country_stats\\\\final_data\\\\aggregated_forest_edge_country.csv\"\n",
    "\n",
    "new_matrix = []\n",
    "\n",
    "with open(file_path, 'r', encoding='ISO-8859-1') as f:\n",
    "    lines = f.readlines()[1:]  # 跳过第一行 (header)\n",
    "    \n",
    "    # 添加新的矩阵的header\n",
    "    new_matrix.append(['country', 'stable', 'stable_per2000','stable_per2020',\n",
    "                       'increase increase','increase increase percent',\n",
    "                       'increase decrease', 'increase decrease percent',\n",
    "                       'decrease increase', 'decrease increase percent',\n",
    "                       'decrease decrease', 'decrease decrease percent',\n",
    "                       'total increase per','total increase',\n",
    "                       'total decrease per','total decrease',\n",
    "                       'forest edge 2000', 'forest edge 2020'])\n",
    "    \n",
    "    for line in lines:\n",
    "        values = line.strip().split(',')\n",
    "        country = values[0]\n",
    "        stable = float(values[1]) + float(values[8]) + float(values[15])\n",
    "        increase_increase = float(values[7]) - float(values[6])\n",
    "        increase_decrease = float(values[9]) - float(values[8])\n",
    "        decrease_increase = float(values[14]) - float(values[15])\n",
    "        decrease_decrease = float(values[16]) - float(values[17])\n",
    "        increase = increase_increase + increase_decrease\n",
    "        decrease = decrease_increase + decrease_decrease\n",
    "\n",
    "        forest_edge_2000 = stable + decrease_increase + decrease_decrease\n",
    "        forest_edge_2020 = stable + increase_increase + increase_decrease\n",
    "        \n",
    "        if stable == 0:\n",
    "            stable_per2000 = -1\n",
    "        else:\n",
    "            stable_per2000 = stable/forest_edge_2000\n",
    "\n",
    "        if stable == 0:\n",
    "            stable_per2020 = -1\n",
    "        else:\n",
    "            stable_per2020 = stable/forest_edge_2020\n",
    "        \n",
    "        if forest_edge_2020 == 0:\n",
    "            increase_increase = -1\n",
    "            increase_decrease = -1\n",
    "            decrease_increase = -1\n",
    "            decrease_decrease = -1\n",
    "            increase_decrease_per = -1\n",
    "            increase_increase_per = -1\n",
    "            decrease_increase_per = -1\n",
    "            decrease_decrease_per = -1\n",
    "            increase_per = -1\n",
    "            decrease_per = -1\n",
    "            increase = -1\n",
    "            decrease = -1\n",
    "            stable = -1\n",
    "            forest_edge_2000 = -1\n",
    "            forest_edge_2020 = -1\n",
    "        else:\n",
    "            increase_decrease_per = increase_decrease/forest_edge_2020\n",
    "            increase_increase_per = increase_increase/forest_edge_2020\n",
    "            decrease_increase_per = decrease_increase/forest_edge_2000\n",
    "            decrease_decrease_per = decrease_decrease/forest_edge_2000\n",
    "\n",
    "            increase_per = increase_increase_per+increase_decrease_per\n",
    "            decrease_per = decrease_increase_per+decrease_decrease_per\n",
    "        new_matrix.append([country, stable,stable_per2000,stable_per2020,\n",
    "                           increase_increase,increase_increase_per,\n",
    "                           increase_decrease,increase_decrease_per,\n",
    "                           decrease_increase,decrease_increase_per,\n",
    "                           decrease_decrease,decrease_decrease_per,\n",
    "                           increase_per,increase,decrease_per,decrease,\n",
    "                           forest_edge_2000, forest_edge_2020])\n",
    "\n",
    "# 将新的矩阵保存为CSV\n",
    "output_file_path = \"G:\\\\Hangkai\\\\Forest_edge\\\\country_stats\\\\final_data\\\\processed_country_data.csv\"\n",
    "with open(output_file_path, 'w', encoding='ISO-8859-1') as f:\n",
    "    for row in new_matrix:\n",
    "        f.write(','.join(map(str, row)) + '\\n')\n",
    "\n",
    "print(f\"Processed data saved to {output_file_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc027741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated data by continent saved to G:\\Hangkai\\Global forest edge\\country_forest_area_output\\aggregated_forest_edge_by_continent_by_continent.csv\n"
     ]
    }
   ],
   "source": [
    "import cartopy.io.shapereader as shpreader\n",
    "\n",
    "# 读取 CSV 文件\n",
    "file_path = \"G:\\\\Hangkai\\\\Forest_edge\\\\country_stats\\\\final_data\\\\processed_country_data.csv\"\n",
    "\n",
    "with open(file_path, 'r', encoding='ISO-8859-1') as f:\n",
    "    lines = f.readlines()\n",
    "    header = lines[0].strip().split(',')\n",
    "    lines = lines[1:]  # 仅获取数据，跳过标题行\n",
    "    \n",
    "    # 使用字典来存储国家数据\n",
    "    data_dict = {}\n",
    "    for line in lines:\n",
    "        values = line.strip().split(',')\n",
    "        country = values[0]\n",
    "        data_dict[country] = [float(i) for i in values[1:]]\n",
    "\n",
    "# 1. 从 natural earth shape file 中获取国家到大洲的映射\n",
    "reader = shpreader.Reader(shpreader.natural_earth(resolution='10m', category='cultural', name='admin_0_countries'))\n",
    "country_continent_mapping = {record.attributes['SOVEREIGNT']: record.attributes['CONTINENT'] for record in reader.records()}\n",
    "\n",
    "# 2. 使用上面的映射按大洲汇总国家数据\n",
    "continent_data_dict = {}\n",
    "\n",
    "for country, data in data_dict.items():\n",
    "    # 获取国家对应的大洲\n",
    "    continent = country_continent_mapping.get(country, None)\n",
    "    if continent:\n",
    "        if continent not in continent_data_dict:\n",
    "            continent_data_dict[continent] = [0] * len(data)\n",
    "        \n",
    "        for i in range(len(data)):\n",
    "            continent_data_dict[continent][i] += data[i]\n",
    "\n",
    "# 3. 保存每个大洲的汇总数据到一个新的CSV文件\n",
    "output_file_path = \"G:\\\\Hangkai\\\\Global forest edge\\\\country_forest_area_output\\\\aggregated_forest_edge_by_continent.csv\"\n",
    "with open(output_file_path, 'w', encoding='ISO-8859-1') as f:\n",
    "    f.write(','.join(header) + '\\n')\n",
    "    for continent, data in continent_data_dict.items():\n",
    "        f.write(','.join([continent] + list(map(str, data))) + '\\n')\n",
    "\n",
    "print(f\"Aggregated data by continent saved to {output_file_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
