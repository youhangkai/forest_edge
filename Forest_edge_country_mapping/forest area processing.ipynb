{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01572e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated data saved to G:\\Hangkai\\Global forest edge\\country_forest_area_output\\aggregated_forest_area_country.csv\n"
     ]
    }
   ],
   "source": [
    "# 读取CSV文件并转换为列表\n",
    "file_path = \"G:\\\\Hangkai\\\\Global forest edge\\\\country_forest_area_output\\\\Forest Area Change.csv\"\n",
    "\n",
    "with open(file_path, 'r', encoding='ISO-8859-1') as f:\n",
    "    lines = f.readlines()\n",
    "    header = lines[0].strip().split(',')\n",
    "    lines = lines[1:]  # 仅获取数据，跳过标题行\n",
    "    \n",
    "    # 使用字典来整合重复的国家数据\n",
    "    data_dict = {}\n",
    "    for line in lines:\n",
    "        values = line.strip().split(',')\n",
    "        country = values[0]\n",
    "        \n",
    "        # 如果国家不在字典中，将其添加到字典中\n",
    "        if country not in data_dict:\n",
    "            data_dict[country] = [float(i) for i in values[1:]]\n",
    "        else:\n",
    "            # 如果国家已经在字典中，累加数据\n",
    "            for i in range(len(data_dict[country])):\n",
    "                data_dict[country][i] += float(values[i + 1])\n",
    "\n",
    "# 创建一个新的矩阵\n",
    "new_matrix = [header]\n",
    "for country, data in data_dict.items():\n",
    "    new_matrix.append([country] + data)\n",
    "\n",
    "# 将新的矩阵保存为CSV\n",
    "output_file_path = \"G:\\\\Hangkai\\\\Global forest edge\\\\country_forest_area_output\\\\aggregated_forest_area_country.csv\"\n",
    "with open(output_file_path, 'w', encoding='ISO-8859-1') as f:\n",
    "    for row in new_matrix:\n",
    "        f.write(','.join(map(str, row)) + '\\n')\n",
    "\n",
    "print(f\"Aggregated data saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6343f678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated data by continent saved to G:\\Hangkai\\Global forest edge\\country_forest_area_output\\aggregated_forest_area_by_continent.csv\n"
     ]
    }
   ],
   "source": [
    "import cartopy.io.shapereader as shpreader\n",
    "\n",
    "# 读取 CSV 文件\n",
    "file_path = \"G:\\\\Hangkai\\\\Global forest edge\\\\country_forest_area_output\\\\aggregated_forest_area_country.csv\"\n",
    "\n",
    "with open(file_path, 'r', encoding='ISO-8859-1') as f:\n",
    "    lines = f.readlines()\n",
    "    header = lines[0].strip().split(',')\n",
    "    lines = lines[1:]  # 仅获取数据，跳过标题行\n",
    "    \n",
    "    # 使用字典来存储国家数据\n",
    "    data_dict = {}\n",
    "    for line in lines:\n",
    "        values = line.strip().split(',')\n",
    "        country = values[0]\n",
    "        data_dict[country] = [float(i) for i in values[1:]]\n",
    "\n",
    "# 1. 从 natural earth shape file 中获取国家到大洲的映射\n",
    "reader = shpreader.Reader(shpreader.natural_earth(resolution='10m', category='cultural', name='admin_0_countries'))\n",
    "country_continent_mapping = {record.attributes['SOVEREIGNT']: record.attributes['CONTINENT'] for record in reader.records()}\n",
    "\n",
    "# 2. 使用上面的映射按大洲汇总国家数据\n",
    "continent_data_dict = {}\n",
    "\n",
    "for country, data in data_dict.items():\n",
    "    # 获取国家对应的大洲\n",
    "    continent = country_continent_mapping.get(country, None)\n",
    "    if continent:\n",
    "        if continent not in continent_data_dict:\n",
    "            continent_data_dict[continent] = [0] * len(data)\n",
    "        \n",
    "        for i in range(len(data)):\n",
    "            continent_data_dict[continent][i] += data[i]\n",
    "\n",
    "# 3. 保存每个大洲的汇总数据到一个新的CSV文件\n",
    "output_file_path = \"G:\\\\Hangkai\\\\Global forest edge\\\\country_forest_area_output\\\\aggregated_forest_area_by_continent.csv\"\n",
    "with open(output_file_path, 'w', encoding='ISO-8859-1') as f:\n",
    "    f.write(','.join(header) + '\\n')\n",
    "    for continent, data in continent_data_dict.items():\n",
    "        f.write(','.join([continent] + list(map(str, data))) + '\\n')\n",
    "\n",
    "print(f\"Aggregated data by continent saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05bb0949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for Asia saved to G:\\Hangkai\\Global forest edge\\country_forest_area_output\\continents\\Asia.csv\n",
      "Data for South America saved to G:\\Hangkai\\Global forest edge\\country_forest_area_output\\continents\\South America.csv\n",
      "Data for Africa saved to G:\\Hangkai\\Global forest edge\\country_forest_area_output\\continents\\Africa.csv\n",
      "Data for Seven seas (open ocean) saved to G:\\Hangkai\\Global forest edge\\country_forest_area_output\\continents\\Seven seas (open ocean).csv\n",
      "Data for North America saved to G:\\Hangkai\\Global forest edge\\country_forest_area_output\\continents\\North America.csv\n",
      "Data for Europe saved to G:\\Hangkai\\Global forest edge\\country_forest_area_output\\continents\\Europe.csv\n",
      "Data for Oceania saved to G:\\Hangkai\\Global forest edge\\country_forest_area_output\\continents\\Oceania.csv\n",
      "Data for Antarctica saved to G:\\Hangkai\\Global forest edge\\country_forest_area_output\\continents\\Antarctica.csv\n"
     ]
    }
   ],
   "source": [
    "import cartopy.io.shapereader as shpreader\n",
    "import os\n",
    "\n",
    "# 读取 CSV 文件\n",
    "file_path = \"G:\\\\Hangkai\\\\Global forest edge\\\\country_forest_area_output\\\\aggregated_forest_area_country.csv\"\n",
    "\n",
    "with open(file_path, 'r', encoding='ISO-8859-1') as f:\n",
    "    lines = f.readlines()\n",
    "    header = lines[0].strip().split(',')\n",
    "    lines = lines[1:]  # 仅获取数据，跳过标题行\n",
    "    \n",
    "    # 使用字典来存储国家数据\n",
    "    data_dict = {}\n",
    "    for line in lines:\n",
    "        values = line.strip().split(',')\n",
    "        country = values[0]\n",
    "        data_dict[country] = [float(i) for i in values[1:]]\n",
    "\n",
    "# 1. 从 natural earth shape file 中获取国家到大洲的映射\n",
    "reader = shpreader.Reader(shpreader.natural_earth(resolution='10m', category='cultural', name='admin_0_countries'))\n",
    "country_continent_mapping = {record.attributes['SOVEREIGNT']: record.attributes['CONTINENT'] for record in reader.records()}\n",
    "\n",
    "# 2. 使用上面的映射按大洲汇总国家数据\n",
    "continent_data_dict = {}\n",
    "\n",
    "for country, data in data_dict.items():\n",
    "    # 获取国家对应的大洲\n",
    "    continent = country_continent_mapping.get(country, None)\n",
    "    if continent:\n",
    "        if continent not in continent_data_dict:\n",
    "            continent_data_dict[continent] = []\n",
    "        continent_data_dict[continent].append([country] + data)\n",
    "\n",
    "# 3. 保存每个大洲的数据到单独的文件\n",
    "output_folder = \"G:\\\\Hangkai\\\\Global forest edge\\\\country_forest_area_output\\\\continents\"\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "for continent, data in continent_data_dict.items():\n",
    "    output_continent_file_path = os.path.join(output_folder, f\"{continent}.csv\")\n",
    "    with open(output_continent_file_path, 'w', encoding='ISO-8859-1') as f:\n",
    "        f.write(','.join(header) + '\\n')\n",
    "        for row in data:\n",
    "            f.write(','.join(map(str, row)) + '\\n')\n",
    "\n",
    "    print(f\"Data for {continent} saved to {output_continent_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
