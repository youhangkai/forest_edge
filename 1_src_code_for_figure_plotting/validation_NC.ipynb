{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf56dba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from rasterio.transform import Affine\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "BASE_DIR = r\"G:\\Hangkai\\Global_Forest_edge_mapping_data\"\n",
    "\n",
    "# 0.01° dynamics rasters\n",
    "DYN_DIR = os.path.join(BASE_DIR, \"Global_001_degree\")\n",
    "DYN_FILES = {\n",
    "    \"id\":     os.path.join(DYN_DIR, \"id.tif\"),\n",
    "    \"ii\":     os.path.join(DYN_DIR, \"ii.tif\"),\n",
    "    \"dd\":     os.path.join(DYN_DIR, \"dd.tif\"),\n",
    "    \"di\":     os.path.join(DYN_DIR, \"di.tif\"),\n",
    "    \"stable\": os.path.join(DYN_DIR, \"stable.tif\"),\n",
    "}\n",
    "CLASSES = [\"id\", \"ii\", \"dd\", \"di\", \"stable\"]\n",
    "\n",
    "# High-res folders (0.00025°)\n",
    "YEARS = [2000, 2005, 2010, 2015, 2020]\n",
    "AREA_DIR_TMPL = os.path.join(BASE_DIR, \"{year}Area\")\n",
    "EDGE_DIR_TMPL = os.path.join(BASE_DIR, \"{year}Edge\")\n",
    "\n",
    "# Sampling from 0.01° pixels\n",
    "N_PER_CLASS = 500\n",
    "SEED = 7\n",
    "MIN_WINNER_VALUE = 0.0        # set >0 to exclude near-zero dynamics\n",
    "MIN_SEPARATION_DEG = 0.20     # within-class minimum spacing (~22 km in latitude)\n",
    "MAX_TRIES_PER_CLASS = 2_000_000\n",
    "\n",
    "# Output structure (per-sample folder)\n",
    "OUT_DIR = os.path.join(BASE_DIR, \"validation_samples_sample_folder\")\n",
    "OUT_CSV = os.path.join(OUT_DIR, f\"samples_fullinfo_{N_PER_CLASS}perclass.csv\")\n",
    "SAMPLES_DIR = os.path.join(OUT_DIR, \"samples\")\n",
    "# OUT_DIR/samples/<class>/sample_00001/{area_5yr.tif, edge_5yr.tif, quicklook.png, meta.txt}\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Utilities\n",
    "# =========================\n",
    "def list_tifs(folder: str) -> List[str]:\n",
    "    return sorted(glob.glob(os.path.join(folder, \"*.tif\")))\n",
    "\n",
    "def haversine_deg(lon1, lat1, lon2, lat2) -> float:\n",
    "    \"\"\"Great-circle distance in degrees (approx).\"\"\"\n",
    "    lon1r, lat1r, lon2r, lat2r = map(np.deg2rad, [lon1, lat1, lon2, lat2])\n",
    "    dlon = lon2r - lon1r\n",
    "    dlat = lat2r - lat1r\n",
    "    a = np.sin(dlat / 2) ** 2 + np.cos(lat1r) * np.cos(lat2r) * np.sin(dlon / 2) ** 2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    return float(np.rad2deg(c))\n",
    "\n",
    "def center_from_transform(transform: Affine, row: int, col: int) -> Tuple[float, float]:\n",
    "    x, y = rasterio.transform.xy(transform, row, col, offset=\"center\")\n",
    "    return float(x), float(y)\n",
    "\n",
    "def pixel_bounds_from_transform(transform: Affine, row: int, col: int) -> Tuple[float, float, float, float]:\n",
    "    \"\"\"\n",
    "    Pixel bounds (left, bottom, right, top) for north-up transform.\n",
    "    \"\"\"\n",
    "    x_ul, y_ul = transform * (col, row)\n",
    "    x_lr, y_lr = transform * (col + 1, row + 1)\n",
    "    left = min(x_ul, x_lr)\n",
    "    right = max(x_ul, x_lr)\n",
    "    bottom = min(y_ul, y_lr)\n",
    "    top = max(y_ul, y_lr)\n",
    "    return left, bottom, right, top\n",
    "\n",
    "def build_bounds_index(tif_paths: List[str]) -> List[Tuple[str, float, float, float, float]]:\n",
    "    out = []\n",
    "    for p in tif_paths:\n",
    "        with rasterio.open(p) as ds:\n",
    "            b = ds.bounds\n",
    "        out.append((p, b.left, b.bottom, b.right, b.top))\n",
    "    return out\n",
    "\n",
    "def find_tile(bounds_index: List[Tuple[str, float, float, float, float]], lon: float, lat: float) -> Optional[str]:\n",
    "    for p, L, B, R, T in bounds_index:\n",
    "        if (lon >= L) and (lon < R) and (lat >= B) and (lat < T):\n",
    "            return p\n",
    "    return None\n",
    "\n",
    "def summarize_arr(arr: np.ndarray, nodata: Optional[float]) -> Tuple[float, float, float]:\n",
    "    \"\"\"sum, mean, valid_frac\"\"\"\n",
    "    if nodata is None:\n",
    "        valid = np.isfinite(arr)\n",
    "    else:\n",
    "        valid = np.isfinite(arr) & (arr != nodata)\n",
    "    valid_n = int(valid.sum())\n",
    "    total_n = arr.size\n",
    "    valid_frac = valid_n / total_n if total_n > 0 else 0.0\n",
    "    if valid_n == 0:\n",
    "        return np.nan, np.nan, 0.0\n",
    "    vals = arr[valid].astype(\"float64\")\n",
    "    return float(vals.sum()), float(vals.mean()), float(valid_frac)\n",
    "\n",
    "def crop_patch_from_tile(tile_path: str, left: float, bottom: float, right: float, top: float):\n",
    "    \"\"\"\n",
    "    Crop raster to bounds. Returns (array, meta, tile_basename) or (None,None,None) on failure.\n",
    "    \"\"\"\n",
    "    with rasterio.open(tile_path) as ds:\n",
    "        w = ds.window(left, bottom, right, top)\n",
    "        w = w.round_offsets().round_lengths()\n",
    "\n",
    "        if w.width <= 0 or w.height <= 0:\n",
    "            return None, None, None\n",
    "\n",
    "        if (w.col_off < 0 or w.row_off < 0 or\n",
    "            w.col_off + w.width > ds.width or\n",
    "            w.row_off + w.height > ds.height):\n",
    "            return None, None, None\n",
    "\n",
    "        arr = ds.read(1, window=w)\n",
    "        out_transform = ds.window_transform(w)\n",
    "\n",
    "        meta = {\n",
    "            \"crs\": ds.crs,\n",
    "            \"nodata\": ds.nodata,\n",
    "            \"dtype\": arr.dtype,\n",
    "            \"height\": arr.shape[0],\n",
    "            \"width\": arr.shape[1],\n",
    "            \"transform\": out_transform,\n",
    "        }\n",
    "        return arr, meta, os.path.basename(tile_path)\n",
    "\n",
    "def write_multiband_tif(out_path: str, bands: List[np.ndarray], meta_ref: dict, band_names: List[str]):\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "    profile = {\n",
    "        \"driver\": \"GTiff\",\n",
    "        \"height\": meta_ref[\"height\"],\n",
    "        \"width\": meta_ref[\"width\"],\n",
    "        \"count\": len(bands),\n",
    "        \"dtype\": meta_ref[\"dtype\"],\n",
    "        \"crs\": meta_ref[\"crs\"],\n",
    "        \"transform\": meta_ref[\"transform\"],\n",
    "        \"nodata\": meta_ref[\"nodata\"],\n",
    "        \"compress\": \"LZW\",\n",
    "    }\n",
    "    with rasterio.open(out_path, \"w\", **profile) as dst:\n",
    "        for i, arr in enumerate(bands, start=1):\n",
    "            dst.write(arr, i)\n",
    "            try:\n",
    "                dst.set_band_description(i, band_names[i - 1])\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "\n",
    "# =========================\n",
    "# QUICKLOOK PNG\n",
    "# =========================\n",
    "def save_quicklook_png(\n",
    "    out_png: str,\n",
    "    area_bands: List[np.ndarray],\n",
    "    edge_bands: List[np.ndarray],\n",
    "    years: List[int],\n",
    "    title_prefix: str = \"\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Layout:\n",
    "      Row 1: Area (first year), Area (last year), Area delta\n",
    "      Row 2: Edge (first year), Edge (last year), Edge delta\n",
    "\n",
    "    - Edge uses LogNorm for readability.\n",
    "    - Deltas use symmetric robust limits around 0.\n",
    "    \"\"\"\n",
    "    y0, y1 = years[0], years[-1]\n",
    "    A0 = area_bands[0].astype(\"float64\")\n",
    "    A1 = area_bands[-1].astype(\"float64\")\n",
    "    E0 = edge_bands[0].astype(\"float64\")\n",
    "    E1 = edge_bands[-1].astype(\"float64\")\n",
    "\n",
    "    dA = A1 - A0\n",
    "    dE = E1 - E0\n",
    "\n",
    "    def robust_minmax(x, lo=2, hi=98):\n",
    "        v = x[np.isfinite(x)]\n",
    "        if v.size == 0:\n",
    "            return 0.0, 1.0\n",
    "        return float(np.percentile(v, lo)), float(np.percentile(v, hi))\n",
    "\n",
    "    # common area scale for A0/A1\n",
    "    a_vmin, a_vmax = robust_minmax(np.concatenate([A0.ravel(), A1.ravel()]))\n",
    "\n",
    "    # edge log scale\n",
    "    e_pos = np.concatenate([E0.ravel(), E1.ravel()])\n",
    "    e_pos = e_pos[np.isfinite(e_pos) & (e_pos > 0)]\n",
    "    if e_pos.size == 0:\n",
    "        e_vmin, e_vmax = 1e-6, 1.0\n",
    "    else:\n",
    "        e_vmin = float(np.percentile(e_pos, 2))\n",
    "        e_vmax = float(np.percentile(e_pos, 98))\n",
    "        e_vmin = max(e_vmin, 1e-6)\n",
    "        e_vmax = max(e_vmax, e_vmin * 10)\n",
    "\n",
    "    def sym_limit(x):\n",
    "        v = x[np.isfinite(x)]\n",
    "        if v.size == 0:\n",
    "            return 1.0\n",
    "        m = float(np.percentile(np.abs(v), 98))\n",
    "        return max(m, 1e-6)\n",
    "\n",
    "    dA_lim = sym_limit(dA)\n",
    "    dE_lim = sym_limit(dE)\n",
    "\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(12, 8), dpi=150)\n",
    "    fig.suptitle(title_prefix, fontsize=12)\n",
    "\n",
    "    # Area\n",
    "    im00 = axes[0, 0].imshow(A0, vmin=a_vmin, vmax=a_vmax)\n",
    "    axes[0, 0].set_title(f\"Area {y0}\")\n",
    "    axes[0, 0].axis(\"off\")\n",
    "    plt.colorbar(im00, ax=axes[0, 0], fraction=0.046, pad=0.04)\n",
    "\n",
    "    im01 = axes[0, 1].imshow(A1, vmin=a_vmin, vmax=a_vmax)\n",
    "    axes[0, 1].set_title(f\"Area {y1}\")\n",
    "    axes[0, 1].axis(\"off\")\n",
    "    plt.colorbar(im01, ax=axes[0, 1], fraction=0.046, pad=0.04)\n",
    "\n",
    "    im02 = axes[0, 2].imshow(dA, vmin=-dA_lim, vmax=dA_lim)\n",
    "    axes[0, 2].set_title(f\"ΔArea {y1}-{y0}\")\n",
    "    axes[0, 2].axis(\"off\")\n",
    "    plt.colorbar(im02, ax=axes[0, 2], fraction=0.046, pad=0.04)\n",
    "\n",
    "    # Edge (log)\n",
    "    im10 = axes[1, 0].imshow(E0, norm=LogNorm(vmin=e_vmin, vmax=e_vmax))\n",
    "    axes[1, 0].set_title(f\"Edge {y0} (log)\")\n",
    "    axes[1, 0].axis(\"off\")\n",
    "    plt.colorbar(im10, ax=axes[1, 0], fraction=0.046, pad=0.04)\n",
    "\n",
    "    im11 = axes[1, 1].imshow(E1, norm=LogNorm(vmin=e_vmin, vmax=e_vmax))\n",
    "    axes[1, 1].set_title(f\"Edge {y1} (log)\")\n",
    "    axes[1, 1].axis(\"off\")\n",
    "    plt.colorbar(im11, ax=axes[1, 1], fraction=0.046, pad=0.04)\n",
    "\n",
    "    im12 = axes[1, 2].imshow(dE, vmin=-dE_lim, vmax=dE_lim)\n",
    "    axes[1, 2].set_title(f\"ΔEdge {y1}-{y0}\")\n",
    "    axes[1, 2].axis(\"off\")\n",
    "    plt.colorbar(im12, ax=axes[1, 2], fraction=0.046, pad=0.04)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    fig.savefig(out_png, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Load dynamics stack (0.01°)\n",
    "# =========================\n",
    "def load_dynamics_stack():\n",
    "    arrays = []\n",
    "    transform = None\n",
    "    nodata = None\n",
    "    H = W = None\n",
    "\n",
    "    for cname in CLASSES:\n",
    "        fp = DYN_FILES[cname]\n",
    "        if not os.path.exists(fp):\n",
    "            raise FileNotFoundError(fp)\n",
    "\n",
    "        with rasterio.open(fp) as ds:\n",
    "            if transform is None:\n",
    "                transform = ds.transform\n",
    "                nodata = ds.nodata\n",
    "                H, W = ds.height, ds.width\n",
    "            else:\n",
    "                if ds.transform != transform or ds.height != H or ds.width != W:\n",
    "                    raise RuntimeError(f\"Dynamics rasters not aligned: {fp}\")\n",
    "\n",
    "            arrays.append(ds.read(1).astype(\"float64\"))\n",
    "\n",
    "    stack = np.stack(arrays, axis=0)  # (5, H, W)\n",
    "    return stack, transform, nodata\n",
    "\n",
    "def compute_winner(stack: np.ndarray, nodata: Optional[float]):\n",
    "    if nodata is None:\n",
    "        valid = np.all(np.isfinite(stack), axis=0)\n",
    "    else:\n",
    "        valid = np.all(np.isfinite(stack) & (stack != nodata), axis=0)\n",
    "\n",
    "    stack_pos = np.clip(stack, 0, None)  # just in case\n",
    "    winner_idx = np.argmax(stack_pos, axis=0)\n",
    "    winner_val = np.take_along_axis(stack_pos, winner_idx[None, ...], axis=0)[0]\n",
    "\n",
    "    valid = valid & (winner_val > MIN_WINNER_VALUE)\n",
    "    return valid, winner_idx, winner_val, stack_pos\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Sampling dominant-class 0.01° pixels\n",
    "# =========================\n",
    "def sample_pixels_per_class(valid, winner_idx, winner_val, stack_pos, transform) -> pd.DataFrame:\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "\n",
    "    records = []\n",
    "\n",
    "    for ci, cname in enumerate(CLASSES):\n",
    "        m = valid & (winner_idx == ci)\n",
    "        rr, cc = np.where(m)\n",
    "        n_cand = rr.size\n",
    "        if n_cand == 0:\n",
    "            print(f\"[Warn] No candidates for class {cname}.\")\n",
    "            continue\n",
    "\n",
    "        order = np.random.permutation(n_cand)\n",
    "        rr = rr[order]\n",
    "        cc = cc[order]\n",
    "\n",
    "        selected_coords = []\n",
    "        idx_ptr = 0\n",
    "        tries = 0\n",
    "\n",
    "        while len(selected_coords) < N_PER_CLASS and tries < MAX_TRIES_PER_CLASS and idx_ptr < n_cand:\n",
    "            tries += 1\n",
    "            r = int(rr[idx_ptr])\n",
    "            c = int(cc[idx_ptr])\n",
    "            idx_ptr += 1\n",
    "\n",
    "            lon, lat = center_from_transform(transform, r, c)\n",
    "\n",
    "            # enforce within-class spacing\n",
    "            ok = True\n",
    "            for slon, slat in selected_coords:\n",
    "                if haversine_deg(lon, lat, slon, slat) < MIN_SEPARATION_DEG:\n",
    "                    ok = False\n",
    "                    break\n",
    "            if not ok:\n",
    "                continue\n",
    "\n",
    "            selected_coords.append((lon, lat))\n",
    "            left, bottom, right, top = pixel_bounds_from_transform(transform, r, c)\n",
    "\n",
    "            rec = {\n",
    "                \"class\": cname,\n",
    "                \"row_001\": r,\n",
    "                \"col_001\": c,\n",
    "                \"center_lon\": lon,\n",
    "                \"center_lat\": lat,\n",
    "                \"pixel_left\": left,\n",
    "                \"pixel_bottom\": bottom,\n",
    "                \"pixel_right\": right,\n",
    "                \"pixel_top\": top,\n",
    "                \"winner_value_001\": float(winner_val[r, c]),\n",
    "            }\n",
    "            for k_i, k_name in enumerate(CLASSES):\n",
    "                rec[f\"dyn_{k_name}_001\"] = float(stack_pos[k_i, r, c])\n",
    "\n",
    "            records.append(rec)\n",
    "\n",
    "        print(f\"Class {cname}: selected {len(selected_coords)} / {N_PER_CLASS} (candidates={n_cand})\")\n",
    "\n",
    "    df = pd.DataFrame(records)\n",
    "    df.insert(0, \"sample_id\", np.arange(1, len(df) + 1))\n",
    "    return df\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Tile indices for high-res area/edge (per year)\n",
    "# =========================\n",
    "def build_tile_bounds_by_year(folder_tmpl: str) -> Dict[int, List[Tuple[str, float, float, float, float]]]:\n",
    "    out = {}\n",
    "    for y in YEARS:\n",
    "        folder = folder_tmpl.format(year=y)\n",
    "        files = list_tifs(folder)\n",
    "        if not files:\n",
    "            raise RuntimeError(f\"No tif in {folder}\")\n",
    "        out[y] = build_bounds_index(files)\n",
    "        print(f\"Indexed {len(out[y])} tiles for {folder}\")\n",
    "    return out\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Extract patches + write per-sample folder (area, edge, quicklook)\n",
    "# =========================\n",
    "def extract_and_write(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    os.makedirs(SAMPLES_DIR, exist_ok=True)\n",
    "\n",
    "    area_bounds = build_tile_bounds_by_year(AREA_DIR_TMPL)\n",
    "    edge_bounds = build_tile_bounds_by_year(EDGE_DIR_TMPL)\n",
    "\n",
    "    out_rows = []\n",
    "    saved = 0\n",
    "    skipped = 0\n",
    "\n",
    "    for _, r in df.iterrows():\n",
    "        sid = int(r[\"sample_id\"])\n",
    "        cname = str(r[\"class\"])\n",
    "        lon = float(r[\"center_lon\"])\n",
    "        lat = float(r[\"center_lat\"])\n",
    "        left = float(r[\"pixel_left\"])\n",
    "        bottom = float(r[\"pixel_bottom\"])\n",
    "        right = float(r[\"pixel_right\"])\n",
    "        top = float(r[\"pixel_top\"])\n",
    "\n",
    "        sample_folder = os.path.join(SAMPLES_DIR, cname, f\"sample_{sid:05d}\")\n",
    "        os.makedirs(sample_folder, exist_ok=True)\n",
    "\n",
    "        rec = r.to_dict()\n",
    "        rec[\"sample_folder\"] = sample_folder\n",
    "\n",
    "        area_bands: List[np.ndarray] = []\n",
    "        edge_bands: List[np.ndarray] = []\n",
    "        area_meta_ref = None\n",
    "        edge_meta_ref = None\n",
    "\n",
    "        ok = True\n",
    "\n",
    "        for y in YEARS:\n",
    "            a_tile = find_tile(area_bounds[y], lon, lat)\n",
    "            e_tile = find_tile(edge_bounds[y], lon, lat)\n",
    "            if a_tile is None or e_tile is None:\n",
    "                ok = False\n",
    "                break\n",
    "\n",
    "            a_arr, a_meta, a_tile_name = crop_patch_from_tile(a_tile, left, bottom, right, top)\n",
    "            e_arr, e_meta, e_tile_name = crop_patch_from_tile(e_tile, left, bottom, right, top)\n",
    "            if a_arr is None or e_arr is None:\n",
    "                ok = False\n",
    "                break\n",
    "\n",
    "            # shape consistency across years\n",
    "            if area_meta_ref is None:\n",
    "                area_meta_ref = a_meta\n",
    "            else:\n",
    "                if (a_meta[\"height\"], a_meta[\"width\"]) != (area_meta_ref[\"height\"], area_meta_ref[\"width\"]):\n",
    "                    ok = False\n",
    "                    break\n",
    "\n",
    "            if edge_meta_ref is None:\n",
    "                edge_meta_ref = e_meta\n",
    "            else:\n",
    "                if (e_meta[\"height\"], e_meta[\"width\"]) != (edge_meta_ref[\"height\"], edge_meta_ref[\"width\"]):\n",
    "                    ok = False\n",
    "                    break\n",
    "\n",
    "            # stats\n",
    "            a_sum, a_mean, a_v = summarize_arr(a_arr, a_meta[\"nodata\"])\n",
    "            e_sum, e_mean, e_v = summarize_arr(e_arr, e_meta[\"nodata\"])\n",
    "\n",
    "            rec[f\"area_tile_{y}\"] = a_tile_name\n",
    "            rec[f\"edge_tile_{y}\"] = e_tile_name\n",
    "\n",
    "            rec[f\"area_sum_{y}\"] = a_sum\n",
    "            rec[f\"area_mean_{y}\"] = a_mean\n",
    "            rec[f\"area_validfrac_{y}\"] = a_v\n",
    "\n",
    "            rec[f\"edge_sum_{y}\"] = e_sum\n",
    "            rec[f\"edge_mean_{y}\"] = e_mean\n",
    "            rec[f\"edge_validfrac_{y}\"] = e_v\n",
    "\n",
    "            area_bands.append(a_arr)\n",
    "            edge_bands.append(e_arr)\n",
    "\n",
    "        if not ok or len(area_bands) != len(YEARS) or len(edge_bands) != len(YEARS):\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        # Write both tifs into the same sample folder\n",
    "        area_out = os.path.join(sample_folder, \"area_5yr.tif\")\n",
    "        edge_out = os.path.join(sample_folder, \"edge_5yr.tif\")\n",
    "\n",
    "        write_multiband_tif(area_out, area_bands, area_meta_ref, [str(y) for y in YEARS])\n",
    "        write_multiband_tif(edge_out, edge_bands, edge_meta_ref, [str(y) for y in YEARS])\n",
    "\n",
    "        rec[\"area_patch_path\"] = area_out\n",
    "        rec[\"edge_patch_path\"] = edge_out\n",
    "\n",
    "        # Quicklook\n",
    "        quicklook_out = os.path.join(sample_folder, \"quicklook.png\")\n",
    "        title_prefix = f\"{cname} | sample {sid:05d} | ({lon:.4f}, {lat:.4f})\"\n",
    "        save_quicklook_png(\n",
    "            out_png=quicklook_out,\n",
    "            area_bands=area_bands,\n",
    "            edge_bands=edge_bands,\n",
    "            years=YEARS,\n",
    "            title_prefix=title_prefix\n",
    "        )\n",
    "        rec[\"quicklook_png_path\"] = quicklook_out\n",
    "\n",
    "        # meta.txt (handy)\n",
    "        meta_txt = os.path.join(sample_folder, \"meta.txt\")\n",
    "        with open(meta_txt, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"sample_id: {sid}\\n\")\n",
    "            f.write(f\"class: {cname}\\n\")\n",
    "            f.write(f\"center_lon, center_lat: {lon}, {lat}\\n\")\n",
    "            f.write(f\"0.01deg pixel bounds (L,B,R,T): {left}, {bottom}, {right}, {top}\\n\\n\")\n",
    "            f.write(\"0.01deg dynamics values:\\n\")\n",
    "            for k in CLASSES:\n",
    "                f.write(f\"  {k}: {rec.get('dyn_'+k+'_001', np.nan)}\\n\")\n",
    "            f.write(\"\\nPer-year tiles and sums:\\n\")\n",
    "            for y in YEARS:\n",
    "                f.write(f\"\\nYear {y}\\n\")\n",
    "                f.write(f\"  area_tile: {rec.get(f'area_tile_{y}','')}\\n\")\n",
    "                f.write(f\"  edge_tile: {rec.get(f'edge_tile_{y}','')}\\n\")\n",
    "                f.write(f\"  area_sum: {rec.get(f'area_sum_{y}',np.nan)}\\n\")\n",
    "                f.write(f\"  edge_sum: {rec.get(f'edge_sum_{y}',np.nan)}\\n\")\n",
    "        rec[\"meta_txt_path\"] = meta_txt\n",
    "\n",
    "        out_rows.append(rec)\n",
    "        saved += 1\n",
    "        if saved % 50 == 0:\n",
    "            print(f\"Saved {saved} samples (skipped={skipped})\")\n",
    "\n",
    "    print(f\"Done. Saved={saved}, Skipped={skipped}\")\n",
    "    return pd.DataFrame(out_rows)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# MAIN\n",
    "# =========================\n",
    "def main():\n",
    "    os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "    stack, transform, nodata = load_dynamics_stack()\n",
    "    valid, winner_idx, winner_val, stack_pos = compute_winner(stack, nodata)\n",
    "\n",
    "    df_points = sample_pixels_per_class(valid, winner_idx, winner_val, stack_pos, transform)\n",
    "    print(f\"Total sampled points (before extraction): {len(df_points)}\")\n",
    "\n",
    "    df_full = extract_and_write(df_points)\n",
    "    df_full.to_csv(OUT_CSV, index=False)\n",
    "    print(f\"Saved CSV: {OUT_CSV}\")\n",
    "    print(df_full.head())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b715266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] G:\\Hangkai\\Global_Forest_edge_mapping_data\\validation_samples_0p01deg_per_sample_folder\\samples\\aaa\\sample_01010_A\\sample_01010_A.kml\n",
      "[OK] G:\\Hangkai\\Global_Forest_edge_mapping_data\\validation_samples_0p01deg_per_sample_folder\\samples\\aaa\\sample_01019_A\\sample_01019_A.kml\n",
      "[OK] G:\\Hangkai\\Global_Forest_edge_mapping_data\\validation_samples_0p01deg_per_sample_folder\\samples\\aaa\\sample_01026_B\\sample_01026_B.kml\n",
      "[OK] G:\\Hangkai\\Global_Forest_edge_mapping_data\\validation_samples_0p01deg_per_sample_folder\\samples\\aaa\\sample_01029_A\\sample_01029_A.kml\n",
      "[OK] G:\\Hangkai\\Global_Forest_edge_mapping_data\\validation_samples_0p01deg_per_sample_folder\\samples\\aaa\\sample_01030_B\\sample_01030_B.kml\n",
      "[OK] G:\\Hangkai\\Global_Forest_edge_mapping_data\\validation_samples_0p01deg_per_sample_folder\\samples\\aaa\\sample_01038_B\\sample_01038_B.kml\n",
      "[OK] G:\\Hangkai\\Global_Forest_edge_mapping_data\\validation_samples_0p01deg_per_sample_folder\\samples\\aaa\\sample_01040_A\\sample_01040_A.kml\n",
      "[OK] G:\\Hangkai\\Global_Forest_edge_mapping_data\\validation_samples_0p01deg_per_sample_folder\\samples\\aaa\\sample_01044_C\\sample_01044_C.kml\n",
      "[OK] G:\\Hangkai\\Global_Forest_edge_mapping_data\\validation_samples_0p01deg_per_sample_folder\\samples\\aaa\\sample_01050_B\\sample_01050_B.kml\n",
      "[OK] G:\\Hangkai\\Global_Forest_edge_mapping_data\\validation_samples_0p01deg_per_sample_folder\\samples\\aaa\\sample_01094_A\\sample_01094_A.kml\n",
      "[OK] G:\\Hangkai\\Global_Forest_edge_mapping_data\\validation_samples_0p01deg_per_sample_folder\\samples\\aaa\\sample_01095_A\\sample_01095_A.kml\n",
      "[OK] G:\\Hangkai\\Global_Forest_edge_mapping_data\\validation_samples_0p01deg_per_sample_folder\\samples\\aaa\\sample_01112_A\\sample_01112_A.kml\n",
      "[OK] G:\\Hangkai\\Global_Forest_edge_mapping_data\\validation_samples_0p01deg_per_sample_folder\\samples\\aaa\\sample_01115_A\\sample_01115_A.kml\n",
      "[OK] G:\\Hangkai\\Global_Forest_edge_mapping_data\\validation_samples_0p01deg_per_sample_folder\\samples\\aaa\\sample_01117_S\\sample_01117_S.kml\n",
      "[OK] G:\\Hangkai\\Global_Forest_edge_mapping_data\\validation_samples_0p01deg_per_sample_folder\\samples\\aaa\\sample_01132_A\\sample_01132_A.kml\n",
      "[OK] G:\\Hangkai\\Global_Forest_edge_mapping_data\\validation_samples_0p01deg_per_sample_folder\\samples\\aaa\\sample_01140_B\\sample_01140_B.kml\n",
      "[OK] G:\\Hangkai\\Global_Forest_edge_mapping_data\\validation_samples_0p01deg_per_sample_folder\\samples\\aaa\\sample_01181_B\\sample_01181_B.kml\n",
      "[OK] G:\\Hangkai\\Global_Forest_edge_mapping_data\\validation_samples_0p01deg_per_sample_folder\\samples\\aaa\\sample_01182_C\\sample_01182_C.kml\n",
      "[OK] G:\\Hangkai\\Global_Forest_edge_mapping_data\\validation_samples_0p01deg_per_sample_folder\\samples\\aaa\\sample_01183_B\\sample_01183_B.kml\n",
      "[OK] G:\\Hangkai\\Global_Forest_edge_mapping_data\\validation_samples_0p01deg_per_sample_folder\\samples\\aaa\\sample_01188_B\\sample_01188_B.kml\n",
      "[OK] G:\\Hangkai\\Global_Forest_edge_mapping_data\\validation_samples_0p01deg_per_sample_folder\\samples\\aaa\\sample_01206_B\\sample_01206_B.kml\n",
      "[OK] G:\\Hangkai\\Global_Forest_edge_mapping_data\\validation_samples_0p01deg_per_sample_folder\\samples\\aaa\\sample_01242_C\\sample_01242_C.kml\n",
      "[OK] G:\\Hangkai\\Global_Forest_edge_mapping_data\\validation_samples_0p01deg_per_sample_folder\\samples\\aaa\\sample_01303_A\\sample_01303_A.kml\n",
      "[OK] G:\\Hangkai\\Global_Forest_edge_mapping_data\\validation_samples_0p01deg_per_sample_folder\\samples\\aaa\\sample_01313_A\\sample_01313_A.kml\n",
      "[OK] G:\\Hangkai\\Global_Forest_edge_mapping_data\\validation_samples_0p01deg_per_sample_folder\\samples\\aaa\\sample_01489_A\\sample_01489_A.kml\n",
      "\n",
      "Done. KML files created: 25\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# =======================\n",
    "# USER PATH\n",
    "# =======================\n",
    "ROOT = r\"G:\\Hangkai\\Global_Forest_edge_mapping_data\\validation_samples_0p01deg_per_sample_folder\\samples\\aaa\"\n",
    "META_FILENAMES = (\"meta.txty\", \"meta.txt\")\n",
    "ADD_CENTER_POINT = True\n",
    "\n",
    "# =======================\n",
    "# REGEX PATTERNS\n",
    "# =======================\n",
    "RE_SAMPLE_ID = re.compile(r\"sample_id\\s*:\\s*(.+)\", re.IGNORECASE)\n",
    "RE_CLASS = re.compile(r\"class\\s*:\\s*(.+)\", re.IGNORECASE)\n",
    "RE_CENTER = re.compile(\n",
    "    r\"center_lon\\s*,\\s*center_lat\\s*:\\s*([-\\d\\.eE]+)\\s*,\\s*([-\\d\\.eE]+)\",\n",
    "    re.IGNORECASE\n",
    ")\n",
    "RE_BOUNDS = re.compile(\n",
    "    r\"0\\.01deg\\s+pixel\\s+bounds\\s*\\(L,B,R,T\\)\\s*:\\s*([-\\d\\.eE]+)\\s*,\\s*([-\\d\\.eE]+)\\s*,\\s*([-\\d\\.eE]+)\\s*,\\s*([-\\d\\.eE]+)\",\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "# =======================\n",
    "# KML GENERATOR\n",
    "# =======================\n",
    "def make_kml(name, bounds, center=None):\n",
    "    west, south, east, north = bounds\n",
    "\n",
    "    polygon_coords = f\"\"\"\n",
    "            {west},{south},0\n",
    "            {east},{south},0\n",
    "            {east},{north},0\n",
    "            {west},{north},0\n",
    "            {west},{south},0\n",
    "    \"\"\"\n",
    "\n",
    "    center_point = \"\"\n",
    "    if ADD_CENTER_POINT and center is not None:\n",
    "        clon, clat = center\n",
    "        center_point = f\"\"\"\n",
    "  <Placemark>\n",
    "    <name>{name}_center</name>\n",
    "    <Point>\n",
    "      <coordinates>{clon},{clat},0</coordinates>\n",
    "    </Point>\n",
    "  </Placemark>\n",
    "\"\"\"\n",
    "\n",
    "    return f\"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "<kml xmlns=\"http://www.opengis.net/kml/2.2\">\n",
    "<Document>\n",
    "  <name>{name}</name>\n",
    "\n",
    "  <Style id=\"box\">\n",
    "    <LineStyle>\n",
    "      <color>ff0000ff</color>\n",
    "      <width>2</width>\n",
    "    </LineStyle>\n",
    "    <PolyStyle>\n",
    "      <color>3f0000ff</color>\n",
    "    </PolyStyle>\n",
    "  </Style>\n",
    "\n",
    "  <Placemark>\n",
    "    <name>{name}</name>\n",
    "    <styleUrl>#box</styleUrl>\n",
    "    <Polygon>\n",
    "      <outerBoundaryIs>\n",
    "        <LinearRing>\n",
    "          <coordinates>\n",
    "{polygon_coords}\n",
    "          </coordinates>\n",
    "        </LinearRing>\n",
    "      </outerBoundaryIs>\n",
    "    </Polygon>\n",
    "  </Placemark>\n",
    "{center_point}\n",
    "</Document>\n",
    "</kml>\n",
    "\"\"\"\n",
    "\n",
    "# =======================\n",
    "# META PARSER\n",
    "# =======================\n",
    "def parse_meta(meta_path):\n",
    "    sample_id = None\n",
    "    cls = None\n",
    "    center = None\n",
    "    bounds = None\n",
    "\n",
    "    for line in meta_path.read_text(encoding=\"utf-8\", errors=\"ignore\").splitlines():\n",
    "        if m := RE_SAMPLE_ID.search(line):\n",
    "            sample_id = m.group(1).strip()\n",
    "        elif m := RE_CLASS.search(line):\n",
    "            cls = m.group(1).strip()\n",
    "        elif m := RE_CENTER.search(line):\n",
    "            center = (float(m.group(1)), float(m.group(2)))\n",
    "        elif m := RE_BOUNDS.search(line):\n",
    "            bounds = tuple(map(float, m.groups()))\n",
    "\n",
    "    return sample_id, cls, center, bounds\n",
    "\n",
    "# =======================\n",
    "# MAIN\n",
    "# =======================\n",
    "def main():\n",
    "    root = Path(ROOT)\n",
    "    count = 0\n",
    "\n",
    "    for subdir, _, files in os.walk(root):\n",
    "        subdir = Path(subdir)\n",
    "        if subdir == root:\n",
    "            continue\n",
    "\n",
    "        meta_path = None\n",
    "        for name in META_FILENAMES:\n",
    "            p = subdir / name\n",
    "            if p.exists():\n",
    "                meta_path = p\n",
    "                break\n",
    "\n",
    "        if meta_path is None:\n",
    "            continue\n",
    "\n",
    "        sample_id, cls, center, bounds = parse_meta(meta_path)\n",
    "\n",
    "        if bounds is None:\n",
    "            print(f\"[SKIP] No bounds in {meta_path}\")\n",
    "            continue\n",
    "\n",
    "        # output KML IN THE SAME SUBFOLDER\n",
    "        kml_name = subdir.name\n",
    "        kml_path = subdir / f\"{kml_name}.kml\"\n",
    "\n",
    "        kml_text = make_kml(kml_name, bounds, center)\n",
    "        kml_path.write_text(kml_text, encoding=\"utf-8\")\n",
    "\n",
    "        print(f\"[OK] {kml_path}\")\n",
    "        count += 1\n",
    "\n",
    "    print(f\"\\nDone. KML files created: {count}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "011b7398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] G:\\Hangkai\\Global_Forest_edge_mapping_data\\validation_samples_0p01deg_per_sample_folder\\samples\\output\\sample_00502\\preview_area_edge_5yr.png\n",
      "[OK] G:\\Hangkai\\Global_Forest_edge_mapping_data\\validation_samples_0p01deg_per_sample_folder\\samples\\output\\sample_00507\\preview_area_edge_5yr.png\n",
      "[OK] G:\\Hangkai\\Global_Forest_edge_mapping_data\\validation_samples_0p01deg_per_sample_folder\\samples\\output\\sample_00508\\preview_area_edge_5yr.png\n",
      "[OK] G:\\Hangkai\\Global_Forest_edge_mapping_data\\validation_samples_0p01deg_per_sample_folder\\samples\\output\\sample_00538\\preview_area_edge_5yr.png\n",
      "[OK] G:\\Hangkai\\Global_Forest_edge_mapping_data\\validation_samples_0p01deg_per_sample_folder\\samples\\output\\sample_00539\\preview_area_edge_5yr.png\n",
      "[OK] G:\\Hangkai\\Global_Forest_edge_mapping_data\\validation_samples_0p01deg_per_sample_folder\\samples\\output\\sample_00540\\preview_area_edge_5yr.png\n",
      "[OK] G:\\Hangkai\\Global_Forest_edge_mapping_data\\validation_samples_0p01deg_per_sample_folder\\samples\\output\\sample_00541\\preview_area_edge_5yr.png\n",
      "[OK] G:\\Hangkai\\Global_Forest_edge_mapping_data\\validation_samples_0p01deg_per_sample_folder\\samples\\output\\sample_00542\\preview_area_edge_5yr.png\n",
      "[OK] G:\\Hangkai\\Global_Forest_edge_mapping_data\\validation_samples_0p01deg_per_sample_folder\\samples\\output\\sample_00545\\preview_area_edge_5yr.png\n",
      "[OK] G:\\Hangkai\\Global_Forest_edge_mapping_data\\validation_samples_0p01deg_per_sample_folder\\samples\\output\\sample_00546\\preview_area_edge_5yr.png\n",
      "[OK] G:\\Hangkai\\Global_Forest_edge_mapping_data\\validation_samples_0p01deg_per_sample_folder\\samples\\output\\sample_00551\\preview_area_edge_5yr.png\n",
      "[OK] G:\\Hangkai\\Global_Forest_edge_mapping_data\\validation_samples_0p01deg_per_sample_folder\\samples\\output\\sample_00552\\preview_area_edge_5yr.png\n",
      "[OK] G:\\Hangkai\\Global_Forest_edge_mapping_data\\validation_samples_0p01deg_per_sample_folder\\samples\\output\\sample_00553\\preview_area_edge_5yr.png\n",
      "[OK] G:\\Hangkai\\Global_Forest_edge_mapping_data\\validation_samples_0p01deg_per_sample_folder\\samples\\output\\sample_00592\\preview_area_edge_5yr.png\n",
      "[OK] G:\\Hangkai\\Global_Forest_edge_mapping_data\\validation_samples_0p01deg_per_sample_folder\\samples\\output\\sample_00598\\preview_area_edge_5yr.png\n",
      "[OK] G:\\Hangkai\\Global_Forest_edge_mapping_data\\validation_samples_0p01deg_per_sample_folder\\samples\\output\\sample_00600\\preview_area_edge_5yr.png\n",
      "[OK] G:\\Hangkai\\Global_Forest_edge_mapping_data\\validation_samples_0p01deg_per_sample_folder\\samples\\output\\sample_00601\\preview_area_edge_5yr.png\n",
      "[OK] G:\\Hangkai\\Global_Forest_edge_mapping_data\\validation_samples_0p01deg_per_sample_folder\\samples\\output\\sample_00605\\preview_area_edge_5yr.png\n",
      "[OK] G:\\Hangkai\\Global_Forest_edge_mapping_data\\validation_samples_0p01deg_per_sample_folder\\samples\\output\\sample_00607\\preview_area_edge_5yr.png\n",
      "[OK] G:\\Hangkai\\Global_Forest_edge_mapping_data\\validation_samples_0p01deg_per_sample_folder\\samples\\output\\sample_00608\\preview_area_edge_5yr.png\n",
      "[OK] G:\\Hangkai\\Global_Forest_edge_mapping_data\\validation_samples_0p01deg_per_sample_folder\\samples\\output\\sample_00610\\preview_area_edge_5yr.png\n",
      "[OK] G:\\Hangkai\\Global_Forest_edge_mapping_data\\validation_samples_0p01deg_per_sample_folder\\samples\\output\\sample_00615\\preview_area_edge_5yr.png\n",
      "[OK] G:\\Hangkai\\Global_Forest_edge_mapping_data\\validation_samples_0p01deg_per_sample_folder\\samples\\output\\sample_00616\\preview_area_edge_5yr.png\n",
      "[OK] G:\\Hangkai\\Global_Forest_edge_mapping_data\\validation_samples_0p01deg_per_sample_folder\\samples\\output\\sample_00679\\preview_area_edge_5yr.png\n",
      "\n",
      "Done. previews created: 24, skipped/errors: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =======================\n",
    "# USER SETTINGS\n",
    "# =======================\n",
    "ROOT = r\"G:\\Hangkai\\Global_Forest_edge_mapping_data\\validation_samples_0p01deg_per_sample_folder\\samples\\output\"\n",
    "AREA_NAME = \"area_5yr.tif\"\n",
    "EDGE_NAME = \"edge_5yr.tif\"\n",
    "YEARS = [2000, 2005, 2010, 2015, 2020]\n",
    "\n",
    "# 生成预览图文件名（每个 subfolder 内）\n",
    "OUT_PNG_NAME = \"preview_area_edge_5yr.png\"\n",
    "\n",
    "# 分位数拉伸，避免极端值影响对比度\n",
    "STRETCH_Q = (2, 98)   # (low, high) percentiles\n",
    "\n",
    "\n",
    "def read_5band_tif(tif_path: Path):\n",
    "    \"\"\"Read a 5-band GeoTIFF into a (5, H, W) float32 array.\"\"\"\n",
    "    with rasterio.open(tif_path) as ds:\n",
    "        if ds.count < 5:\n",
    "            raise ValueError(f\"{tif_path} has {ds.count} bands, expected >= 5.\")\n",
    "        arr = ds.read(list(range(1, 6))).astype(np.float32)  # (5, H, W)\n",
    "    return arr\n",
    "\n",
    "\n",
    "def mask_invalid(arr):\n",
    "    \"\"\"Mask values <= 0 as invalid (NaN).\"\"\"\n",
    "    out = arr.copy()\n",
    "    out[out <= 0] = np.nan\n",
    "    return out\n",
    "\n",
    "\n",
    "def robust_vmin_vmax(arr, q=(2, 98)):\n",
    "    \"\"\"Compute robust display range ignoring NaNs.\"\"\"\n",
    "    flat = arr[np.isfinite(arr)]\n",
    "    if flat.size == 0:\n",
    "        return 0.0, 1.0\n",
    "    vmin, vmax = np.percentile(flat, q)\n",
    "    if np.isclose(vmin, vmax):\n",
    "        # fallback if almost constant\n",
    "        vmin = float(np.nanmin(arr)) if np.isfinite(arr).any() else 0.0\n",
    "        vmax = float(np.nanmax(arr)) if np.isfinite(arr).any() else 1.0\n",
    "        if np.isclose(vmin, vmax):\n",
    "            vmax = vmin + 1.0\n",
    "    return float(vmin), float(vmax)\n",
    "\n",
    "\n",
    "def make_preview(area_5, edge_5, out_png: Path, title: str):\n",
    "    \"\"\"\n",
    "    area_5, edge_5: (5, H, W) with NaNs for invalid\n",
    "    Save a 5x2 grid: rows=years, cols=[area, edge]\n",
    "    \"\"\"\n",
    "    # set display ranges separately for area & edge (robust)\n",
    "    area_vmin, area_vmax = robust_vmin_vmax(area_5, STRETCH_Q)\n",
    "    edge_vmin, edge_vmax = robust_vmin_vmax(edge_5, STRETCH_Q)\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=5, ncols=2,\n",
    "        figsize=(10, 18),\n",
    "        dpi=150,\n",
    "        constrained_layout=True\n",
    "    )\n",
    "\n",
    "    for i, yr in enumerate(YEARS):\n",
    "        ax_a = axes[i, 0]\n",
    "        ax_e = axes[i, 1]\n",
    "\n",
    "        a = area_5[i]\n",
    "        e = edge_5[i]\n",
    "\n",
    "        im_a = ax_a.imshow(a, vmin=area_vmin, vmax=area_vmax)\n",
    "        ax_a.set_title(f\"Area {yr}\")\n",
    "        ax_a.set_axis_off()\n",
    "\n",
    "        im_e = ax_e.imshow(e, vmin=edge_vmin, vmax=edge_vmax)\n",
    "        ax_e.set_title(f\"Edge {yr}\")\n",
    "        ax_e.set_axis_off()\n",
    "\n",
    "    # colorbars (one for each column)\n",
    "    cbar_a = fig.colorbar(im_a, ax=axes[:, 0], fraction=0.02, pad=0.01)\n",
    "    cbar_a.set_label(\"Area value (masked <= 0)\")\n",
    "\n",
    "    cbar_e = fig.colorbar(im_e, ax=axes[:, 1], fraction=0.02, pad=0.01)\n",
    "    cbar_e.set_label(\"Edge value (masked <= 0)\")\n",
    "\n",
    "    fig.suptitle(title, fontsize=14)\n",
    "    fig.savefig(out_png, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def main():\n",
    "    root = Path(ROOT)\n",
    "    if not root.exists():\n",
    "        raise FileNotFoundError(f\"ROOT not found: {root}\")\n",
    "\n",
    "    n_done, n_skip = 0, 0\n",
    "\n",
    "    for subdir, _, _ in os.walk(root):\n",
    "        subdir = Path(subdir)\n",
    "        if subdir == root:\n",
    "            continue\n",
    "\n",
    "        area_path = subdir / AREA_NAME\n",
    "        edge_path = subdir / EDGE_NAME\n",
    "        if not (area_path.exists() and edge_path.exists()):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            area_5 = mask_invalid(read_5band_tif(area_path))\n",
    "            edge_5 = mask_invalid(read_5band_tif(edge_path))\n",
    "\n",
    "            out_png = subdir / OUT_PNG_NAME\n",
    "            title = f\"{subdir.name} | {AREA_NAME} & {EDGE_NAME}\"\n",
    "            make_preview(area_5, edge_5, out_png, title)\n",
    "\n",
    "            print(f\"[OK] {out_png}\")\n",
    "            n_done += 1\n",
    "        except Exception as e:\n",
    "            print(f\"[SKIP] {subdir} -> {e}\")\n",
    "            n_skip += 1\n",
    "\n",
    "    print(f\"\\nDone. previews created: {n_done}, skipped/errors: {n_skip}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
